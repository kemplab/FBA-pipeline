{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline - Protein prediction pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary User Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "input_folder = 'Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Files for TCGA, CCLE, GTEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCGA\n",
    "'GSM1536837_06_01_15_TCGA_24.tumor_Rsubread_TPM.txt' - Go to https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM1536837, download file\n",
    "\n",
    "'GSM1697009_06_01_15_TCGA_24.normal_Rsubread_TPM.txt' - Go to https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM1697009, download file\n",
    "\n",
    "Place files in 'input\\TCGA\\setup\\', run 'input\\TCGA\\setup\\setup.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCLE\n",
    "'CCLE_RNAseq_rsem_genes_tpm_20180929.txt' - Go to https://portals.broadinstitute.org/ccle/data, download 'CCLE_RNAseq_rsem_genes_tpm_20180929.txt.gz', unzip file\n",
    "\n",
    "Place file in 'input\\CCLE\\setup\\', run 'input\\CCLE\\setup\\setup.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTEx\n",
    "'GTEx_Analysis_2016-01-15_v7_RNASeQCv1.1.8_gene_tpm.gct' - Go to https://www.gtexportal.org/home/datasets, download 'GTEx_Analysis_2016-01-15_v7_RNASeQCv1.1.8_gene_tpm.gct.gz', unzip file\n",
    "\n",
    "Place file in 'input\\GTEx\\setup\\', run 'input\\GTEx\\setup\\setup.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('output/%s' % input_folder):\n",
    "    output_folder = input_folder\n",
    "    os.mkdir('output/%s' % output_folder)\n",
    "else:\n",
    "    val = 1\n",
    "    made_folder = False\n",
    "    while not made_folder:\n",
    "        if not os.path.isdir('output/%s_%d' % (input_folder,val)):\n",
    "            output_folder = '%s_%d' % (input_folder,val)\n",
    "            os.mkdir('output/%s' % output_folder)\n",
    "            made_folder = True\n",
    "        else:\n",
    "            val += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create standard output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('output/%s/_files_' % output_folder)\n",
    "fn_stdout = 'output/%s/_files_/stdout.txt' % output_folder\n",
    "with open(fn_stdout,'w') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create standard error file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_stderr = 'output/%s/_files_/stderr.txt' % output_folder\n",
    "with open(fn_stderr,'w') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error catching variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_error = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "        \n",
    "    # load options\n",
    "    df_options = pd.read_excel('input/%s/_OPTIONS_.xlsx' % input_folder, sheet_name='Input', header=None)\n",
    "       \n",
    "    # file name\n",
    "    options_fn = str(df_options.loc[0][1])\n",
    "    \n",
    "    # excel sheet name\n",
    "    options_excel_sheet = str(df_options.loc[3][2])\n",
    "    \n",
    "    # file delimiter\n",
    "    #options_delimiter = str(df_options.loc[6][2].decode('unicode_escape'))\n",
    "    options_delimiter = str(df_options.loc[6][2])\n",
    "    \n",
    "    # rna-seq normalization\n",
    "    options_rnaseq = str(df_options.loc[9][3])\n",
    "    \n",
    "    # header row\n",
    "    options_header = int(df_options.loc[17][2])\n",
    "    \n",
    "    # gene/transcript ID column\n",
    "    options_geneid_column = int(df_options.loc[24][3])\n",
    "    \n",
    "    # gene ID type\n",
    "    options_geneid_type = str(df_options.loc[27][3])\n",
    "    \n",
    "    # samples format\n",
    "    samplesformat_option1 = str(df_options.loc[35][0])\n",
    "    samplesformat_option2 = str(df_options.loc[36][0])\n",
    "    if samplesformat_option1 == 'X' and samplesformat_option2 != 'X':\n",
    "        samplesformat = 'manual'\n",
    "    elif samplesformat_option1 != 'X' and samplesformat_option2 == 'X':\n",
    "        samplesformat = 'automatic'\n",
    "    elif samplesformat_option1 != 'X' and samplesformat_option2 != 'X':\n",
    "        with open(fn_stderr,'a') as f:\n",
    "            f.write('ERROR - Options File - RNA-Seq - Samples Format - Must select samples format with \"X\"\\n')\n",
    "        found_error = True\n",
    "    else:\n",
    "        with open(fn_stderr,'a') as f:\n",
    "            f.write('ERROR - Options File - RNA-Seq - Samples Format - Can only select one samples format\\n')\n",
    "        found_error = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manual Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if samplesformat == 'manual':\n",
    "        \n",
    "        # load samples\n",
    "        df_sample = pd.read_excel('input/%s/_OPTIONS_.xlsx' % input_folder, sheet_name='Manual Samples', header=None)\n",
    "        \n",
    "        # initialize list\n",
    "        sample_columns_ = []\n",
    "        sample_names_ = []\n",
    "\n",
    "        # extract data\n",
    "        for i in range(1,df_sample.shape[0]):\n",
    "            if (isinstance(df_sample.loc[i][1],str)):\n",
    "                \n",
    "                # sample name\n",
    "                sample_names_.append(str(df_sample.loc[i][1]))\n",
    "\n",
    "                # sample column\n",
    "                if (isinstance(df_sample.loc[i][0],(str,float,int))):\n",
    "                    sample_columns_.append(int(df_sample.loc[i][0]))\n",
    "                else:\n",
    "                    with open(fn_stderr,'a') as f:\n",
    "                        f.write('ERROR - Options File - Manual Samples - Missing sample column for sample \"%s\"\\n' % str(df_sample.loc[i][3]))\n",
    "                    found_error = True\n",
    "            \n",
    "        # error if no samples\n",
    "        if len(sample_names_) == 0:\n",
    "            with open(fn_stderr,'a') as f:\n",
    "                f.write('ERROR - Options File - Manual Samples - Must have at least one sample\\n')\n",
    "            found_error = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process manual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if samplesformat == 'manual':\n",
    "\n",
    "        # get unique sample names\n",
    "        sample_names = list(set(sample_names_))\n",
    "\n",
    "        # sample column\n",
    "        sample_columns = []\n",
    "        for sample in sample_names:\n",
    "            sample_columns.append([])\n",
    "            for i in range(len(sample_names_)):\n",
    "                if sample_names_[i] == sample:\n",
    "                    sample_columns[-1].append(sample_columns_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load gene ID conversions and transcript lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    # load data\n",
    "    with open('_data_/geneids/geneids.pkl','rb') as f:\n",
    "        ensembltranscript_length, genesymbol_length, convert_ensembltranscript_genesymbol, convert_geneid_genesymbol, convert_ensemblgeneid_genesymbol, convert_refseqtranscript_ensembltranscript = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Recon3 gene list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joshu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "recon_genes = sorted(pd.read_table('../recon/genes.tsv')['SYMBOL'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Schwanhausser data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    # k_sp and k_dp parameters\n",
    "    df_schwanhausser = pd.read_csv('_data_/schwanhausser/parameters.csv')\n",
    "    schwanhausser_genes = df_schwanhausser['GENE'].tolist()\n",
    "    schwanhausser_ksp = df_schwanhausser['KSP [1/hr]'].tolist()\n",
    "    schwanhausser_kdp = df_schwanhausser['KDP [1/hr]'].tolist()\n",
    "\n",
    "    # total cellular protein number\n",
    "    with open('_data_/schwanhausser/protein_number.txt','r') as f:\n",
    "        schwanhausser_protein_number = float(f.readlines()[0])\n",
    "\n",
    "    # total cellular mRNA number\n",
    "    with open('_data_/schwanhausser/mrna_number.txt','r') as f:\n",
    "        schwanhausser_mrna_number = float(f.readlines()[0])\n",
    "        \n",
    "    # conversion factor for each recon gene\n",
    "    conversion_factor = []\n",
    "    for gene in recon_genes:\n",
    "        if gene in schwanhausser_genes:\n",
    "            conversion_factor.append(1./1000000*schwanhausser_mrna_number*schwanhausser_ksp[schwanhausser_genes.index(gene)]/schwanhausser_kdp[schwanhausser_genes.index(gene)]/schwanhausser_protein_number*1000000)\n",
    "        else:\n",
    "            conversion_factor.append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load PaxDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    # load data\n",
    "    with open('_data_/paxdb/paxdb.pkl','rb') as f:\n",
    "        recongenes_averageabundance = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Process RNA-seq data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joshu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\joshu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "if not found_error:\n",
    "    \n",
    "    # file extension\n",
    "    file_extension = options_fn.split('.')[-1]\n",
    "\n",
    "    # load data\n",
    "    if file_extension in ['xls','xlsx']:\n",
    "        df_data = pd.read_excel('input/%s/%s' % (input_folder,options_fn), sheet_name=options_excel_sheet, skiprows=range(options_header-1), index_col=None)\n",
    "    else:\n",
    "        df_data = pd.read_table('input/%s/%s' % (input_folder,options_fn), delimiter=options_delimiter, skiprows=range(options_header-1), index_col=None)\n",
    "\n",
    "    # extract gene ID's\n",
    "    data_ids = [str(x) for x in df_data[df_data.columns[options_geneid_column-1]].tolist()] \n",
    "        \n",
    "    # automatic sample names\n",
    "    if samplesformat == 'automatic':\n",
    "        sample_names = df_data.columns.tolist()[options_header:]\n",
    "        sample_columns = [[x] for x in range(options_header+1,df_data.shape[1]+1)]\n",
    "        \n",
    "    # extract data\n",
    "    data_gene = []\n",
    "    for i in range(len(sample_names)):\n",
    "        data_gene.append(df_data[df_data.columns[[x-1 for x in sample_columns[i]]]])\n",
    "\n",
    "        # set index to gene ID's\n",
    "        data_gene[-1].index = data_ids\n",
    "\n",
    "        # sum values with same gene ID\n",
    "        data_gene[-1] = data_gene[-1].groupby(data_gene[-1].index).sum()\n",
    "\n",
    "    # new list of gene ID's\n",
    "    data_ids = data_gene[-1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gene ID & Ensembl Gene ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert gene ID's to gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if options_geneid_type in ['Gene ID','Ensembl Gene ID']:\n",
    "            \n",
    "        # initialize gene symbols\n",
    "        ids_query = []\n",
    "        ids_symbols = []\n",
    "            \n",
    "        # gene ID\n",
    "        if options_geneid_type == 'Gene ID':\n",
    "            \n",
    "            # iterate over data ids\n",
    "            for i in range(len(data_ids)):\n",
    "                if int(data_ids[i]) in convert_geneid_genesymbol:\n",
    "                    ids_query.append(data_ids[i])\n",
    "                    ids_symbols.append(convert_geneid_genesymbol[int(data_ids[i])])\n",
    "                else:\n",
    "                    with open(fn_stdout,'a') as f:\n",
    "                        f.write('Gene ID Conversion - Gene ID \"%s\" not available and removed from dataset\\n' % str(data_ids[i]))  \n",
    "                        \n",
    "        # ensembl gene ID\n",
    "        elif options_geneid_type == 'Ensembl Gene ID':\n",
    "            \n",
    "            # iterate over data ids\n",
    "            for i in range(len(data_ids)):\n",
    "                if str(data_ids[i]) in convert_ensemblgeneid_genesymbol:\n",
    "                    ids_query.extend([data_ids[i] for x in convert_ensemblgeneid_genesymbol[str(data_ids[i])]])\n",
    "                    ids_symbols.extend(convert_ensemblgeneid_genesymbol[str(data_ids[i])])\n",
    "                else:\n",
    "                    with open(fn_stdout,'a') as f:\n",
    "                        f.write('Gene ID Conversion - Ensembl Gene ID \"%s\" not available and removed from dataset\\n' % str(data_ids[i]))\n",
    "            \n",
    "        # iterate over samples\n",
    "        for i in range(len(sample_names)):\n",
    "                \n",
    "            # replace gene ID's with symbols\n",
    "            data_gene[i] = data_gene[i].loc[ids_query]\n",
    "            data_gene[i].index = ids_symbols\n",
    "                \n",
    "            # sum values with same gene symbol\n",
    "            data_gene[i] = data_gene[i].groupby(data_gene[i].index).sum()\n",
    "                \n",
    "        # new list of gene ID's\n",
    "        data_ids = data_gene[-1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gene Symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if options_geneid_type == 'Gene Symbol':\n",
    "            \n",
    "        # symbols to keep\n",
    "        data_ids = [x for x in data_ids if x in genesymbol_length]\n",
    "            \n",
    "        # iterate over samples\n",
    "        for i in range(len(sample_names)):\n",
    "                \n",
    "            # replace gene ID's with symbols\n",
    "            data_gene[i] = data_gene[i].loc[data_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to TPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if options_geneid_type in ['Gene Symbol','Gene ID','Ensembl Gene ID']:\n",
    "            \n",
    "        # counts\n",
    "        if options_rnaseq == 'Count':\n",
    "                \n",
    "            # get length of largest transcript for that gene in Kb\n",
    "            data_lengths = [genesymbol_length[gene]/1000. for gene in data_ids]\n",
    "                \n",
    "            # iterate over samples\n",
    "            for i in range(len(sample_names)):\n",
    "\n",
    "                # divide gene values by largest length\n",
    "                data_gene[i] = data_gene[i].div(data_lengths, axis=0)\n",
    "                    \n",
    "        # RPKM/FPKM\n",
    "        if options_rnaseq in ['Count','RPKM','FPKM','TPM']:\n",
    "                \n",
    "            # iterate over samples\n",
    "            for i in range(len(sample_names)):\n",
    "\n",
    "                # convert to TPM: divide by sum of sample values, multiply by 1000000\n",
    "                data_gene[i] = data_gene[i].div(data_gene[i].sum(axis=0), axis=1) * 1000000      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensembl Transcript ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if options_geneid_type == 'Ensembl Transcript ID':\n",
    "            \n",
    "        # symbols to keep\n",
    "        data_ids = [x for x in data_ids if x in ensembltranscript_length]\n",
    "            \n",
    "        # iterate over samples\n",
    "        for i in range(len(sample_names)):\n",
    "                \n",
    "            # replace gene ID's with symbols\n",
    "            data_gene[i] = data_gene[i].loc[data_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Divide counts by transcript length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if options_geneid_type == 'Ensembl Transcript ID':\n",
    "        if options_rnaseq == 'Count':\n",
    "                \n",
    "            # get length of transcript in Kb\n",
    "            data_lengths = [ensembltranscript_length[transcript]/1000. for transcript in data_ids]\n",
    "                \n",
    "            # iterate over samples\n",
    "            for i in range(len(sample_names)):\n",
    "\n",
    "                # divide gene values by largest length\n",
    "                data_gene[i] = data_gene[i].div(data_lengths, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert transcript ID's to gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if options_geneid_type == 'Ensembl Transcript ID':\n",
    "            \n",
    "        # initialize gene symbols\n",
    "        ids_query = []\n",
    "        ids_symbols = []\n",
    "           \n",
    "        # ensembl transcript ID\n",
    "        if options_geneid_type == 'Ensembl Transcript ID':\n",
    "            \n",
    "            # iterate over data ids\n",
    "            for i in range(len(data_ids)):\n",
    "                if str(data_ids[i]) in convert_ensembltranscript_genesymbol:\n",
    "                    ids_query.extend([data_ids[i] for x in convert_ensembltranscript_genesymbol[str(data_ids[i])]])\n",
    "                    ids_symbols.extend(convert_ensembltranscript_genesymbol[str(data_ids[i])])\n",
    "                else:\n",
    "                    with open(fn_stdout,'a') as f:\n",
    "                        f.write('Gene ID Conversion - Ensembl Transcript ID \"%s\" not available and removed from dataset\\n' % str(data_ids[i]))\n",
    "            \n",
    "        # iterate over samples\n",
    "        for i in range(len(sample_names)):\n",
    "                \n",
    "            # replace transcript ID's with gene symbols\n",
    "            data_gene[i] = data_gene[i].loc[ids_query]\n",
    "            data_gene[i].index = ids_symbols\n",
    "                \n",
    "            # sum values with same gene symbol\n",
    "            data_gene[i] = data_gene[i].groupby(data_gene[i].index).sum()\n",
    "                \n",
    "        # new list of gene ID's\n",
    "        data_ids = data_gene[-1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to TPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if options_geneid_type == 'Ensembl Transcript ID':\n",
    "                    \n",
    "        # RPKM/FPKM\n",
    "        if options_rnaseq in ['Count','RPKM','FPKM','TPM']:\n",
    "                \n",
    "            # iterate over samples\n",
    "            for i in range(len(sample_names)):\n",
    "\n",
    "                # convert to TPM: divide by sum of sample values, multiply by 1000000\n",
    "                data_gene[i] = data_gene[i].div(data_gene[i].sum(axis=0), axis=1) * 1000000      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restrict to Recon3 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    \n",
    "    # iterate over samples\n",
    "    for i in range(len(sample_names)):\n",
    "        \n",
    "        # restrict to recon genes\n",
    "        data_gene[i] = data_gene[i].reindex(recon_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take average of replicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    # iterate over samples\n",
    "    for i in range(len(sample_names)):\n",
    "        \n",
    "        # replace 0's with nan's\n",
    "        data_gene[i] = data_gene[i].replace(0, np.nan)\n",
    "        \n",
    "        # take average of replicates\n",
    "        data_gene[i] = data_gene[i].mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge data for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    data_gene = pd.concat(data_gene, axis=1, sort=False)\n",
    "    data_gene.columns = sample_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert gene counts to protein counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Schwanhausser method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    # multiply TPM values by conversion factor to get PPM\n",
    "    data_protein = data_gene.multiply(conversion_factor, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression within each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    \n",
    "    # iterate over samples\n",
    "    for i in range(len(sample_names)):\n",
    "        \n",
    "        # extract gene and protein expression\n",
    "        protein_all = data_protein[sample_names[i]].tolist()\n",
    "        gene_all = data_gene[sample_names[i]].tolist()\n",
    "        keep_index = [a for a in range(len(protein_all)) if (not np.isnan(protein_all[a])) and (not np.isnan(gene_all[a]))]\n",
    "        protein = [protein_all[a] for a in keep_index]\n",
    "        gene = [gene_all[a] for a in keep_index]\n",
    "        \n",
    "        # linear regression of gene vs. protein expression\n",
    "        reg = LinearRegression().fit([[x] for x in np.log10(gene)], np.log10(protein))\n",
    "        \n",
    "        # predict missing protein values with given gene values\n",
    "        calculate_index = [a for a in range(len(protein_all)) if (np.isnan(protein_all[a])) and (not np.isnan(gene_all[a]))]\n",
    "        gene_predict = data_gene.loc[[recon_genes[a] for a in calculate_index]][sample_names[i]].tolist()\n",
    "        data_protein.loc[[recon_genes[a] for a in calculate_index],sample_names[i]] = [10**x for x in reg.predict([[x] for x in np.log10(gene_predict)])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average PaxDB expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    \n",
    "    # iterate over samples\n",
    "    for i in range(len(sample_names)):\n",
    "        \n",
    "        # iterate over missing values\n",
    "        for gene in [x for x in data_protein.index if np.isnan(data_protein.loc[x][sample_names[i]])]:\n",
    "            \n",
    "            # if gene in PaxDB data\n",
    "            if gene in recongenes_averageabundance:\n",
    "            \n",
    "                # fill in average PaxDB expression for that gene\n",
    "                data_protein.loc[gene,sample_names[i]] = recongenes_averageabundance[gene]\n",
    "            \n",
    "            # otherwise. fill with average PaxDB expression for all genes\n",
    "            else:\n",
    "                data_protein.loc[gene,sample_names[i]] = recongenes_averageabundance['_ALL_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "#### Export protein expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joshu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "if not found_error:\n",
    "    \n",
    "    # iterate over samples\n",
    "    for i in range(len(sample_names)):\n",
    "        \n",
    "        # export data\n",
    "        data_protein[sample_names[i]].to_csv('output/%s/%s.csv' % (output_folder, sample_names[i].replace('/','-')), header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

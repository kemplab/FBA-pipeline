{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import gmean, hmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = 'GTEx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('output/%s' % input_folder):\n",
    "    output_folder = input_folder\n",
    "    os.mkdir('output/%s' % output_folder)\n",
    "else:\n",
    "    val = 1\n",
    "    made_folder = False\n",
    "    while not made_folder:\n",
    "        if not os.path.isdir('output/%s_%d' % (input_folder,val)):\n",
    "            output_folder = '%s_%d' % (input_folder,val)\n",
    "            os.mkdir('output/%s' % output_folder)\n",
    "            made_folder = True\n",
    "        else:\n",
    "            val += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create standard output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('output/%s/_files_' % output_folder)\n",
    "fn_stdout = 'output/%s/_files_/stdout.txt' % output_folder\n",
    "with open(fn_stdout,'w') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create standard error file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_stderr = 'output/%s/_files_/stderr.txt' % output_folder\n",
    "with open(fn_stderr,'w') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error catching variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_error = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sheet\n",
    "df_options = pd.read_excel('input/%s/_OPTIONS_.xlsx' % input_folder, sheet_name='Data Type', header=None)\n",
    "\n",
    "# data type\n",
    "datatype_option1 = str(df_options.loc[1][0])\n",
    "datatype_option2 = str(df_options.loc[2][0])\n",
    "datatype_option3 = str(df_options.loc[3][0])\n",
    "if datatype_option1 == 'X' and datatype_option2 != 'X' and datatype_option3 != 'X':\n",
    "    datatype = 'rnaseq'\n",
    "elif datatype_option1 != 'X' and datatype_option2 == 'X' and datatype_option3 != 'X':\n",
    "    datatype = 'gpl570'\n",
    "elif datatype_option1 != 'X' and datatype_option2 != 'X' and datatype_option3 == 'X':\n",
    "    datatype = 'gpl10558'\n",
    "elif datatype_option1 != 'X' and datatype_option2 != 'X' and datatype_option3 != 'X':\n",
    "    with open(fn_stderr,'a') as f:\n",
    "        f.write('ERROR - Options File - Data Type - Must select data type with \"X\"\\n')\n",
    "    found_error = True\n",
    "else:\n",
    "    with open(fn_stderr,'a') as f:\n",
    "        f.write('ERROR - Options File - Data Type - Can only select one data type\\n')\n",
    "    found_error = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RNA-Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'rnaseq':\n",
    "        \n",
    "        # load options\n",
    "        df_options = pd.read_excel('input/%s/_OPTIONS_.xlsx' % input_folder, sheet_name='RNA-Seq', header=None)\n",
    "        \n",
    "        # file name\n",
    "        options_fn = str(df_options.loc[0][1])\n",
    "        \n",
    "        # excel sheet name\n",
    "        options_excel_sheet = str(df_options.loc[3][2])\n",
    "        \n",
    "        # file delimiter\n",
    "        #options_delimiter = str(df_options.loc[6][2].decode('unicode_escape'))\n",
    "        options_delimiter = str(df_options.loc[6][2])\n",
    "        \n",
    "        # rna-seq normalization\n",
    "        options_rnaseq = str(df_options.loc[9][3])\n",
    "        \n",
    "        # header row\n",
    "        options_header = int(df_options.loc[17][2])\n",
    "        \n",
    "        # gene/transcript ID column\n",
    "        options_geneid_column = int(df_options.loc[24][3])\n",
    "        \n",
    "        # gene ID type\n",
    "        options_geneid_type = str(df_options.loc[27][3])\n",
    "        \n",
    "        # samples format\n",
    "        samplesformat_option1 = str(df_options.loc[35][0])\n",
    "        samplesformat_option2 = str(df_options.loc[36][0])\n",
    "        if samplesformat_option1 == 'X' and samplesformat_option2 != 'X':\n",
    "            samplesformat = 'manual'\n",
    "        elif samplesformat_option1 != 'X' and samplesformat_option2 == 'X':\n",
    "            samplesformat = 'automatic'\n",
    "        elif samplesformat_option1 != 'X' and samplesformat_option2 != 'X':\n",
    "            with open(fn_stderr,'a') as f:\n",
    "                f.write('ERROR - Options File - RNA-Seq - Samples Format - Must select samples format with \"X\"\\n')\n",
    "            found_error = True\n",
    "        else:\n",
    "            with open(fn_stderr,'a') as f:\n",
    "                f.write('ERROR - Options File - RNA-Seq - Samples Format - Can only select one samples format\\n')\n",
    "            found_error = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPL570"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'gpl570':\n",
    "        \n",
    "        # load options\n",
    "        df_options = pd.read_excel('input/%s/_OPTIONS_.xlsx' % input_folder, sheet_name='GPL570', header=None)\n",
    "        \n",
    "        # file extension\n",
    "        options_extension = str(df_options.loc[0][2])\n",
    "        if options_extension not in ['.cel','.CEL']:\n",
    "            with open(fn_stderr,'a') as f:\n",
    "                f.write('ERROR - Options File - GPL570 - Files Extension - Must be either \".cel\" or \".CEL\"\\n')\n",
    "            found_error = True\n",
    "        \n",
    "        # samples format\n",
    "        samplesformat_option1 = str(df_options.loc[4][0])\n",
    "        samplesformat_option2 = str(df_options.loc[5][0])\n",
    "        if samplesformat_option1 == 'X' and samplesformat_option2 != 'X':\n",
    "            samplesformat = 'manual'\n",
    "        elif samplesformat_option1 != 'X' and samplesformat_option2 == 'X':\n",
    "            samplesformat = 'automatic'\n",
    "        elif samplesformat_option1 != 'X' and samplesformat_option2 != 'X':\n",
    "            with open(fn_stderr,'a') as f:\n",
    "                f.write('ERROR - Options File - GPL570 - Samples Format - Must select samples format with \"X\"\\n')\n",
    "            found_error = True\n",
    "        else:\n",
    "            with open(fn_stderr,'a') as f:\n",
    "                f.write('ERROR - Options File - GPL570 - Samples Format - Can only select one samples format\\n')\n",
    "            found_error = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPL10558"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'gpl10558':\n",
    "        \n",
    "        # load options\n",
    "        df_options = pd.read_excel('input/%s/_OPTIONS_.xlsx' % input_folder, sheet_name='GPL10558', header=None)\n",
    "        \n",
    "        # file name\n",
    "        options_fn = str(df_options.loc[0][1])\n",
    "        \n",
    "        # excel sheet name\n",
    "        options_excel_sheet = str(df_options.loc[3][2])\n",
    "        \n",
    "        # file delimiter\n",
    "        options_delimiter = str(df_options.loc[6][2])\n",
    "\n",
    "        # header row\n",
    "        options_header = int(df_options.loc[9][2])\n",
    "        \n",
    "        # probe ID column\n",
    "        options_probeid_column = int(df_options.loc[16][2])\n",
    "        \n",
    "        # samples format\n",
    "        samplesformat_option1 = str(df_options.loc[20][0])\n",
    "        samplesformat_option2 = str(df_options.loc[21][0])\n",
    "        if samplesformat_option1 == 'X' and samplesformat_option2 != 'X':\n",
    "            samplesformat = 'manual'\n",
    "        elif samplesformat_option1 != 'X' and samplesformat_option2 == 'X':\n",
    "            samplesformat = 'automatic'\n",
    "        elif samplesformat_option1 != 'X' and samplesformat_option2 != 'X':\n",
    "            with open(fn_stderr,'a') as f:\n",
    "                f.write('ERROR - Options File - GPL10558 - Samples Format - Must select samples format with \"X\"\\n')\n",
    "            found_error = True\n",
    "        else:\n",
    "            with open(fn_stderr,'a') as f:\n",
    "                f.write('ERROR - Options File - GPL10558 - Samples Format - Can only select one samples format\\n')\n",
    "            found_error = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manual Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if samplesformat == 'manual':\n",
    "        \n",
    "        # load samples\n",
    "        df_sample = pd.read_excel('input/%s/_OPTIONS_.xlsx' % input_folder, sheet_name='Manual Samples', header=None)\n",
    "        \n",
    "        # initialize list\n",
    "        if datatype == 'gpl570':\n",
    "            sample_files_ = []\n",
    "        if datatype in ['rnaseq','gpl10558']:\n",
    "            sample_columns_ = []\n",
    "        if datatype == 'gpl10558':\n",
    "            pvalue_columns_ = []\n",
    "        sample_names_ = []\n",
    "\n",
    "        # extract data\n",
    "        for i in range(1,df_sample.shape[0]):\n",
    "            if (isinstance(df_sample.loc[i][3],str)):\n",
    "                \n",
    "                # sample name\n",
    "                sample_names_.append(str(df_sample.loc[i][3]))\n",
    "                \n",
    "                # sample file\n",
    "                if datatype == 'gpl570':\n",
    "                    if (isinstance(df_sample.loc[i][0],(str,float))):\n",
    "                        sample_files_.append(str(df_sample.loc[i][0]))\n",
    "                    else:\n",
    "                        with open(fn_stderr,'a') as f:\n",
    "                            f.write('ERROR - Options File - Manual Samples - Missing sample file for sample \"%s\"\\n' % str(df_sample.loc[i][3]))\n",
    "                        found_error = True\n",
    "                        \n",
    "                # sample column\n",
    "                if datatype in ['rnaseq','gpl10558']:\n",
    "                    if (isinstance(df_sample.loc[i][1],(str,float,int))):\n",
    "                        sample_columns_.append(int(df_sample.loc[i][1]))\n",
    "                    else:\n",
    "                        with open(fn_stderr,'a') as f:\n",
    "                            f.write('ERROR - Options File - Manual Samples - Missing sample column for sample \"%s\"\\n' % str(df_sample.loc[i][3]))\n",
    "                        found_error = True\n",
    "                        \n",
    "                # p-value column\n",
    "                if datatype == 'gpl10558':\n",
    "                    if (isinstance(df_sample.loc[i][2],(str,float,int))):\n",
    "                        pvalue_columns_.append(int(df_sample.loc[i][2]))\n",
    "                    else:\n",
    "                        with open(fn_stderr,'a') as f:\n",
    "                            f.write('ERROR - Options File - Manual Samples - Missing p-value column for sample \"%s\"\\n' % str(df_sample.loc[i][3]))\n",
    "                        found_error = True\n",
    "            \n",
    "        # error if no samples\n",
    "        if len(sample_names_) == 0:\n",
    "            with open(fn_stderr,'a') as f:\n",
    "                f.write('ERROR - Options File - Manual Samples - Must have at least one sample\\n')\n",
    "            found_error = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process manual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if samplesformat == 'manual':\n",
    "\n",
    "        # get unique sample names\n",
    "        sample_names = list(set(sample_names_))\n",
    "\n",
    "        # sample file\n",
    "        if datatype == 'gpl570':\n",
    "            sample_files = []\n",
    "            for sample in sample_names:\n",
    "                sample_files.append([])\n",
    "                for i in range(len(sample_names_)):\n",
    "                    if sample_names_[i] == sample:\n",
    "                        sample_files[-1].append(sample_files_[i])\n",
    "\n",
    "        # sample column\n",
    "        if datatype in ['rnaseq','gpl10558']:\n",
    "            sample_columns = []\n",
    "            for sample in sample_names:\n",
    "                sample_columns.append([])\n",
    "                for i in range(len(sample_names_)):\n",
    "                    if sample_names_[i] == sample:\n",
    "                        sample_columns[-1].append(sample_columns_[i])\n",
    "\n",
    "        # p-value column\n",
    "        if datatype == 'gpl10558':\n",
    "            pvalue_columns = []\n",
    "            for sample in sample_names:\n",
    "                pvalue_columns.append([])\n",
    "                for i in range(len(sample_names_)):\n",
    "                    if sample_names_[i] == sample:\n",
    "                        pvalue_columns[-1].append(pvalue_columns_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load gene ID conversions and transcript lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    # load data\n",
    "    with open('_data_/geneids/geneids.pkl','rb') as f:\n",
    "        ensembltranscript_length, genesymbol_length, convert_ensembltranscript_genesymbol, convert_geneid_genesymbol, convert_ensemblgeneid_genesymbol, convert_refseqtranscript_ensembltranscript = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load microarray-RNAseq conversion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    \n",
    "    # spline function\n",
    "    def piecewise_linear(x, x0, y0, k1, k2):\n",
    "        return np.piecewise(x, [x < x0], [lambda x:k1*x + y0-k1*x0, lambda x:k2*x + y0-k2*x0])\n",
    "    \n",
    "    # gpl570\n",
    "    if datatype == 'gpl570':\n",
    "        with open('_data_/microarray/models/affy-gpl570.pkl','r') as f:\n",
    "            p = pickle.load(f)\n",
    "    \n",
    "    # gpl570\n",
    "    if datatype == 'gpl10558':\n",
    "        with open('_data_/microarray/models/illumina-gpl10558.pkl','r') as f:\n",
    "            p = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Recon3 gene list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joshu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "recon_genes = sorted(pd.read_table('../recon/genes.tsv')['SYMBOL'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Schwanhausser data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    # k_sp and k_dp parameters\n",
    "    df_schwanhausser = pd.read_csv('_data_/schwanhausser/parameters.csv')\n",
    "    schwanhausser_genes = df_schwanhausser['GENE'].tolist()\n",
    "    schwanhausser_ksp = df_schwanhausser['KSP [1/hr]'].tolist()\n",
    "    schwanhausser_kdp = df_schwanhausser['KDP [1/hr]'].tolist()\n",
    "\n",
    "    # total cellular protein number\n",
    "    with open('_data_/schwanhausser/protein_number.txt','r') as f:\n",
    "        schwanhausser_protein_number = float(f.readlines()[0])\n",
    "\n",
    "    # total cellular mRNA number\n",
    "    with open('_data_/schwanhausser/mrna_number.txt','r') as f:\n",
    "        schwanhausser_mrna_number = float(f.readlines()[0])\n",
    "        \n",
    "    # conversion factor for each recon gene\n",
    "    conversion_factor = []\n",
    "    for gene in recon_genes:\n",
    "        if gene in schwanhausser_genes:\n",
    "            conversion_factor.append(1./1000000*schwanhausser_mrna_number*schwanhausser_ksp[schwanhausser_genes.index(gene)]/schwanhausser_kdp[schwanhausser_genes.index(gene)]/schwanhausser_protein_number*1000000)\n",
    "        else:\n",
    "            conversion_factor.append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load PaxDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    # load data\n",
    "    with open('_data_/paxdb/paxdb.pkl','rb') as f:\n",
    "        recongenes_averageabundance = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA-Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joshu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\joshu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'rnaseq':\n",
    "    \n",
    "        # file extension\n",
    "        file_extension = options_fn.split('.')[-1]\n",
    "\n",
    "        # load data\n",
    "        if file_extension in ['xls','xlsx']:\n",
    "            df_data = pd.read_excel('input/%s/%s' % (input_folder,options_fn), sheet_name=options_excel_sheet, skiprows=range(options_header-1), index_col=None)\n",
    "        else:\n",
    "            df_data = pd.read_table('input/%s/%s' % (input_folder,options_fn), delimiter=options_delimiter, skiprows=range(options_header-1), index_col=None)\n",
    "\n",
    "        # extract gene ID's\n",
    "        data_ids = [str(x) for x in df_data[df_data.columns[options_geneid_column-1]].tolist()] \n",
    "        \n",
    "        # automatic sample names\n",
    "        if samplesformat == 'automatic':\n",
    "            sample_names = df_data.columns.tolist()[options_header:]\n",
    "            sample_columns = [[x] for x in range(options_header+1,df_data.shape[1]+1)]\n",
    "        \n",
    "        # extract data\n",
    "        data_gene = []\n",
    "        for i in range(len(sample_names)):\n",
    "            data_gene.append(df_data[df_data.columns[[x-1 for x in sample_columns[i]]]])\n",
    "\n",
    "            # set index to gene ID's\n",
    "            data_gene[-1].index = data_ids\n",
    "\n",
    "            # sum values with same gene ID\n",
    "            data_gene[-1] = data_gene[-1].groupby(data_gene[-1].index).sum()\n",
    "\n",
    "        # new list of gene ID's\n",
    "        data_ids = data_gene[-1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gene ID & Ensembl Gene ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert gene ID's to gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'rnaseq':\n",
    "        if options_geneid_type in ['Gene ID','Ensembl Gene ID']:\n",
    "            \n",
    "            # initialize gene symbols\n",
    "            ids_query = []\n",
    "            ids_symbols = []\n",
    "            \n",
    "            # gene ID\n",
    "            if options_geneid_type == 'Gene ID':\n",
    "            \n",
    "                # iterate over data ids\n",
    "                for i in range(len(data_ids)):\n",
    "                    if int(data_ids[i]) in convert_geneid_genesymbol:\n",
    "                        ids_query.append(data_ids[i])\n",
    "                        ids_symbols.append(convert_geneid_genesymbol[int(data_ids[i])])\n",
    "                    else:\n",
    "                        with open(fn_stdout,'a') as f:\n",
    "                            f.write('Gene ID Conversion - Gene ID \"%s\" not available and removed from dataset\\n' % str(data_ids[i]))  \n",
    "                        \n",
    "            # ensembl gene ID\n",
    "            elif options_geneid_type == 'Ensembl Gene ID':\n",
    "            \n",
    "                # iterate over data ids\n",
    "                for i in range(len(data_ids)):\n",
    "                    if str(data_ids[i]) in convert_ensemblgeneid_genesymbol:\n",
    "                        ids_query.extend([data_ids[i] for x in convert_ensemblgeneid_genesymbol[str(data_ids[i])]])\n",
    "                        ids_symbols.extend(convert_ensemblgeneid_genesymbol[str(data_ids[i])])\n",
    "                    else:\n",
    "                        with open(fn_stdout,'a') as f:\n",
    "                            f.write('Gene ID Conversion - Ensembl Gene ID \"%s\" not available and removed from dataset\\n' % str(data_ids[i]))\n",
    "            \n",
    "            # iterate over samples\n",
    "            for i in range(len(sample_names)):\n",
    "                \n",
    "                # replace gene ID's with symbols\n",
    "                data_gene[i] = data_gene[i].loc[ids_query]\n",
    "                data_gene[i].index = ids_symbols\n",
    "                \n",
    "                # sum values with same gene symbol\n",
    "                data_gene[i] = data_gene[i].groupby(data_gene[i].index).sum()\n",
    "                \n",
    "            # new list of gene ID's\n",
    "            data_ids = data_gene[-1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gene Symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'rnaseq':\n",
    "        if options_geneid_type == 'Gene Symbol':\n",
    "            \n",
    "            # symbols to keep\n",
    "            data_ids = [x for x in data_ids if x in genesymbol_length]\n",
    "            \n",
    "            # iterate over samples\n",
    "            for i in range(len(sample_names)):\n",
    "                \n",
    "                # replace gene ID's with symbols\n",
    "                data_gene[i] = data_gene[i].loc[data_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to TPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'rnaseq':\n",
    "        if options_geneid_type in ['Gene Symbol','Gene ID','Ensembl Gene ID']:\n",
    "            \n",
    "            # counts\n",
    "            if options_rnaseq == 'Count':\n",
    "                \n",
    "                # get length of largest transcript for that gene in Kb\n",
    "                data_lengths = [genesymbol_length[gene]/1000. for gene in data_ids]\n",
    "                \n",
    "                # iterate over samples\n",
    "                for i in range(len(sample_names)):\n",
    "\n",
    "                    # divide gene values by largest length\n",
    "                    data_gene[i] = data_gene[i].div(data_lengths, axis=0)\n",
    "                    \n",
    "            # RPKM/FPKM\n",
    "            if options_rnaseq in ['Count','RPKM','FPKM','TPM']:\n",
    "                \n",
    "                # iterate over samples\n",
    "                for i in range(len(sample_names)):\n",
    "\n",
    "                    # convert to TPM: divide by sum of sample values, multiply by 1000000\n",
    "                    data_gene[i] = data_gene[i].div(data_gene[i].sum(axis=0), axis=1) * 1000000      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensembl Transcript ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'rnaseq':\n",
    "        if options_geneid_type == 'Ensembl Transcript ID':\n",
    "            \n",
    "            # symbols to keep\n",
    "            data_ids = [x for x in data_ids if x in ensembltranscript_length]\n",
    "            \n",
    "            # iterate over samples\n",
    "            for i in range(len(sample_names)):\n",
    "                \n",
    "                # replace gene ID's with symbols\n",
    "                data_gene[i] = data_gene[i].loc[data_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Divide counts by transcript length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'rnaseq':\n",
    "        if options_geneid_type == 'Ensembl Transcript ID':\n",
    "            if options_rnaseq == 'Count':\n",
    "                \n",
    "                # get length of transcript in Kb\n",
    "                data_lengths = [ensembltranscript_length[transcript]/1000. for transcript in data_ids]\n",
    "                \n",
    "                # iterate over samples\n",
    "                for i in range(len(sample_names)):\n",
    "\n",
    "                    # divide gene values by largest length\n",
    "                    data_gene[i] = data_gene[i].div(data_lengths, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert transcript ID's to gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'rnaseq':\n",
    "        if options_geneid_type == 'Ensembl Transcript ID':\n",
    "            \n",
    "            # initialize gene symbols\n",
    "            ids_query = []\n",
    "            ids_symbols = []\n",
    "           \n",
    "            # ensembl transcript ID\n",
    "            if options_geneid_type == 'Ensembl Transcript ID':\n",
    "            \n",
    "                # iterate over data ids\n",
    "                for i in range(len(data_ids)):\n",
    "                    if str(data_ids[i]) in convert_ensembltranscript_genesymbol:\n",
    "                        ids_query.extend([data_ids[i] for x in convert_ensembltranscript_genesymbol[str(data_ids[i])]])\n",
    "                        ids_symbols.extend(convert_ensembltranscript_genesymbol[str(data_ids[i])])\n",
    "                    else:\n",
    "                        with open(fn_stdout,'a') as f:\n",
    "                            f.write('Gene ID Conversion - Ensembl Transcript ID \"%s\" not available and removed from dataset\\n' % str(data_ids[i]))\n",
    "            \n",
    "            # iterate over samples\n",
    "            for i in range(len(sample_names)):\n",
    "                \n",
    "                # replace transcript ID's with gene symbols\n",
    "                data_gene[i] = data_gene[i].loc[ids_query]\n",
    "                data_gene[i].index = ids_symbols\n",
    "                \n",
    "                # sum values with same gene symbol\n",
    "                data_gene[i] = data_gene[i].groupby(data_gene[i].index).sum()\n",
    "                \n",
    "            # new list of gene ID's\n",
    "            data_ids = data_gene[-1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to TPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'rnaseq':\n",
    "        if options_geneid_type == 'Ensembl Transcript ID':\n",
    "                    \n",
    "            # RPKM/FPKM\n",
    "            if options_rnaseq in ['Count','RPKM','FPKM','TPM']:\n",
    "                \n",
    "                # iterate over samples\n",
    "                for i in range(len(sample_names)):\n",
    "\n",
    "                    # convert to TPM: divide by sum of sample values, multiply by 1000000\n",
    "                    data_gene[i] = data_gene[i].div(data_gene[i].sum(axis=0), axis=1) * 1000000      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affymetrix Human Genome U133 Plus 2.0 Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run SCAN on file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'gpl570':\n",
    "\n",
    "        # write file list\n",
    "        os.mkdir('output/%s/_processing_' % output_folder)\n",
    "        fn_input = 'output/%s/_processing_/input.txt' % output_folder\n",
    "        fn_output = 'output/%s/_processing_/output.txt' % output_folder\n",
    "        with open(fn_input,'w') as f_in:\n",
    "            with open(fn_output,'w') as f_out:\n",
    "                for i in range(len(sample_names)):\n",
    "                    for fn in sample_files[i]:\n",
    "\n",
    "                        # check .CEL file extension\n",
    "                        if options_extension in fn:\n",
    "                            f_in.write('input/%s/%s\\n' % (input_folder, fn))\n",
    "                            f_out.write('output/%s/_processing_/scan/%s\\n' % (output_folder, fn))\n",
    "                        else:\n",
    "                            f_in.write('input/%s/%s%s\\n' % (input_folder, fn, options_extension))\n",
    "                            f_out.write('output/%s/_processing_/scan/%s%s\\n' % (output_folder, fn, options_extension))\n",
    "        \n",
    "        # initialize scan folder\n",
    "        os.mkdir('output/%s/_processing_/scan' % output_folder)\n",
    "        \n",
    "        # run scan on file list\n",
    "        os.system('Rscript --vanilla _data_/microarray/scan/affy-gpl570.R %s %s' % (fn_input, fn_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'gpl570':\n",
    "\n",
    "        # iterate over samples\n",
    "        data_gene = []\n",
    "        for i in range(len(sample_names)):\n",
    "            data = []\n",
    "            \n",
    "            # load replicates\n",
    "            for j in range(len(sample_files[i])):\n",
    "                if options_extension in sample_files[i][j]:\n",
    "                    data.append(pd.read_table('output/%s/_processing_/scan/%s' % (output_folder, sample_files[i][j])))\n",
    "                else:\n",
    "                    data.append(pd.read_table('output/%s/_processing_/scan/%s%s\\n' % (output_folder, sample_files[i][j], options_extension)))\n",
    "\n",
    "            # merge replicates\n",
    "            data_gene.append(pd.concat(data, axis=1, sort=False))\n",
    "            data_gene[-1].index = [x.split('_at')[0].split('.')[0] for x in data_gene[-1].index.tolist()]\n",
    "            \n",
    "        # list of gene ID's\n",
    "        data_ids = data_gene[-1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset Ensembl transcript ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'gpl570':\n",
    "        \n",
    "        # iterate over samples\n",
    "        for i in range(len(sample_names)):\n",
    "\n",
    "            # subset\n",
    "            data_gene[i] = data_gene[i].loc[[x for x in data_ids if x in ensembltranscript_length]]\n",
    "            \n",
    "        # list of gene ID's\n",
    "        data_ids = data_gene[-1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to RNA-Seq values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'gpl570':\n",
    "        \n",
    "        # iterate over samples\n",
    "        for i in range(len(sample_names)):\n",
    "            \n",
    "            # iterate over replicates\n",
    "            for column in data_gene[i].columns.tolist():\n",
    "                \n",
    "                # convert data\n",
    "                data_gene[i].loc[:,column] = [10**x for x in piecewise_linear(data_gene[i][column].values.tolist(), *p)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert transcript ID's to gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'gpl570':\n",
    "            \n",
    "            # initialize gene symbols\n",
    "            ids_query = []\n",
    "            ids_symbols = []\n",
    "            \n",
    "            # iterate over data ids\n",
    "            for i in range(len(data_ids)):\n",
    "                if str(data_ids[i]) in convert_ensembltranscript_genesymbol:\n",
    "                    ids_query.extend([data_ids[i] for x in convert_ensembltranscript_genesymbol[str(data_ids[i])]])\n",
    "                    ids_symbols.extend(convert_ensembltranscript_genesymbol[str(data_ids[i])])\n",
    "                else:\n",
    "                    with open(fn_stdout,'a') as f:\n",
    "                        f.write('Gene ID Conversion - Ensembl Transcript ID \"%s\" not available and removed from dataset\\n' % str(data_ids[i]))\n",
    "            \n",
    "            # iterate over samples\n",
    "            for i in range(len(sample_names)):\n",
    "                \n",
    "                # replace transcript ID's with gene symbols\n",
    "                data_gene[i] = data_gene[i].loc[ids_query]\n",
    "                data_gene[i].index = ids_symbols\n",
    "                \n",
    "                # sum values with same gene symbol\n",
    "                data_gene[i] = data_gene[i].groupby(data_gene[i].index).sum()\n",
    "                \n",
    "            # new list of gene ID's\n",
    "            data_ids = data_gene[-1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to TPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    if datatype == 'gpl570':\n",
    "        \n",
    "        # iterate over samples\n",
    "        for i in range(len(sample_names)):\n",
    "\n",
    "            # convert to TPM: divide by sum of sample values, multiply by 1000000\n",
    "            data_gene[i] = data_gene[i].div(data_gene[i].sum(axis=0), axis=1) * 1000000      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict to Recon3 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    \n",
    "    # iterate over samples\n",
    "    for i in range(len(sample_names)):\n",
    "        \n",
    "        # restrict to recon genes\n",
    "        data_gene[i] = data_gene[i].reindex(recon_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take average of replicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    # iterate over samples\n",
    "    for i in range(len(sample_names)):\n",
    "        \n",
    "        # replace 0's with nan's\n",
    "        data_gene[i] = data_gene[i].replace(0, np.nan)\n",
    "        \n",
    "        # take average of replicates\n",
    "        data_gene[i] = data_gene[i].mean(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    data_gene = pd.concat(data_gene, axis=1, sort=False)\n",
    "    data_gene.columns = sample_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert gene counts to protein counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Schwanhausser method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "\n",
    "    # multiply TPM values by conversion factor to get PPM\n",
    "    data_protein = data_gene.multiply(conversion_factor, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression within each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    \n",
    "    # iterate over samples\n",
    "    for i in range(len(sample_names)):\n",
    "        \n",
    "        # extract gene and protein expression\n",
    "        protein_all = data_protein[sample_names[i]].tolist()\n",
    "        gene_all = data_gene[sample_names[i]].tolist()\n",
    "        keep_index = [a for a in range(len(protein_all)) if (not np.isnan(protein_all[a])) and (not np.isnan(gene_all[a]))]\n",
    "        protein = [protein_all[a] for a in keep_index]\n",
    "        gene = [gene_all[a] for a in keep_index]\n",
    "        \n",
    "        # linear regression of gene vs. protein expression\n",
    "        reg = LinearRegression().fit([[x] for x in np.log10(gene)], np.log10(protein))\n",
    "        \n",
    "        # predict missing protein values with given gene values\n",
    "        calculate_index = [a for a in range(len(protein_all)) if (np.isnan(protein_all[a])) and (not np.isnan(gene_all[a]))]\n",
    "        gene_predict = data_gene.loc[[recon_genes[a] for a in calculate_index]][sample_names[i]].tolist()\n",
    "        data_protein.loc[[recon_genes[a] for a in calculate_index],sample_names[i]] = [10**x for x in reg.predict([[x] for x in np.log10(gene_predict)])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average PaxDB expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not found_error:\n",
    "    \n",
    "    # iterate over samples\n",
    "    for i in range(len(sample_names)):\n",
    "        \n",
    "        # iterate over missing values\n",
    "        for gene in [x for x in data_protein.index if np.isnan(data_protein.loc[x][sample_names[i]])]:\n",
    "            \n",
    "            # if gene in PaxDB data\n",
    "            if gene in recongenes_averageabundance:\n",
    "            \n",
    "                # fill in average PaxDB expression for that gene\n",
    "                data_protein.loc[gene,sample_names[i]] = recongenes_averageabundance[gene]\n",
    "            \n",
    "            # otherwise. fill with average PaxDB expression for all genes\n",
    "            else:\n",
    "                data_protein.loc[gene,sample_names[i]] = recongenes_averageabundance['_ALL_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export protein expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\joshu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "if not found_error:\n",
    "    \n",
    "    # iterate over samples\n",
    "    for i in range(len(sample_names)):\n",
    "        \n",
    "        # export data\n",
    "        data_protein[sample_names[i]].to_csv('output/%s/%s.csv' % (output_folder, sample_names[i].replace('/','-')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
